#!/usr/bin/env python2

import csv
import sys
from sys import stdout, stderr
import os
import argparse
import redis

class RetainValueIterator(object):
    def __init__(self, f):
        self.f=f
        self.val=None

    def __iter__(self):
        return self

    def next(self):
        self.val=self.f.next()
        return self.val

def compare(file1, file2, id_column, redis,
        ignore_columns=[], add=True, scan=True):
    """
    Compare two csv files using Redis

    file1 - The first file
    file2 - The second file
    id_column - The name of the column containing the unique ID

    redis - Redis connection

    ignore_columns - columns to ignore
    add - add data indicator
    scan - scan data indicator
    """
    # get a couple of csv readers from the files
    f1=open(file1, 'rb')
    r1=RetainValueIterator(f1)
    csv1=csv.reader(r1)
    header1=csv1.next()

    f2=open(file2, 'rb')
    r2=RetainValueIterator(f2)
    csv2=csv.reader(r2)
    header2=csv2.next()

    if (header1 != header2):
        raise Exception ('The header rows do not match')

    if id_column not in header1:
        raise Exception('The id coumn specified does not exist')

    try:
        ignore_indexes=[header1.index(a) for a in ignore_columns]
    except ValueError:
        raise Exception('One or more of the specified ignore columns does ' \
            'not exist')

    id_column_index=header1.index(id_column)
    hashable_indexes=[a for a in range(len(header1)) if a not in ignore_indexes]

    if add:
        # read the data into redis
        stderr.write('Entering data into Redis\n')

        # [filename, csv_reader, retain_iterator, line_number,
        #     completion_status, other_item]
        d1=[file1, csv1, r1, 1, False, None]
        d2=[file2, csv2, r2, 1, False, d1]
        d1[5]=d2
        d=d1
        # While both items have yet to complete
        while not d[4] or not d[5][4]:
            try:
                # next row
                row=d[1].next()
                # csv text
                csv_text=d[2].val
                # row count
                d[3]+=1
                if len(row):
                    # key=filename, val=unique_id
                    key=d[0]
                    val=row[id_column_index]
                    redis.sadd(key, val)

                    # key=filename:hashed, val=unique_id:hashed_value
                    hashed_key='%s:hashed' % (d[0],)
                    hashed_val='%s:%025d' % (row[id_column_index],hash(
                        ','.join([row[x] for x in hashable_indexes])))
                    redis.sadd(hashed_key, hashed_val)

                    # memory optimization...
                    # if the other set has this hashed key/val pair
                    if redis.sismember('%s:hashed' % (d[5][0],), hashed_val):
                        # clear the other key
                        redis.delete('%s:%s' % (d[5][0], row[id_column_index]))
                        # do not add this key/value to the list
                    else:
                        key='%s:%s' % (d[0], row[id_column_index],)
                        val='%010d,%s' % (d[3], csv_text)
                        redis.set(key, val)

                # file switching every 100,000 rows
                if d[3] % 100000 == 0 and not d[5][4]:
                    d=d[5]

            except StopIteration:
                d[4]=True
                d=d[5]

        stderr.write('All data has been entered into Redis\n')

    if scan:
        stderr.write('Scanning for new IDs\n')
        first_iteration=True
        for r in redis.sdiff(file1, file2):
            if first_iteration:
                stderr.write('IDs in %s and NOT in %s\n' % (file1, file2))
                first_iteration=False
            stderr.write('%s\n' % (r))

        first_iteration=True
        for r in redis.sdiff(file2, file1):
            if first_iteration:
                stderr.write('IDs in %s and NOT in %s\n' % (file2, file1))
                first_iteration=False
            stderr.write('%s\n' % (r))

        first_iteration=True
        for r in redis.sinter(file1, file2):
            csv1=redis.get('%s:%s' % (file1,r,))
            # if csv1 exists, it was not removed by our memory optimization
            if csv1:
                csv2=redis.get('%s:%s' % (file2,r,))
                if csv2:
                    if first_iteration:
                        first_iteration=False
                        sys.stderr.write(
                            'Writing mismatched results to stdout\n')
                        sys.stdout.write(
                            'file,line,%s\n' % (','.join(header1)),)
                    stdout.write('%s,%s,%s' % \
                        (file1, str(int(csv1[:10])), csv1[11:]))
                    stdout.write('%s,%s,%s' % \
                        (file2, str(int(csv2[:10])), csv2[11:]))

def main(argv=None):
    if argv is None:
        argv = sys.argv

    parser=argparse.ArgumentParser(description='compare two csv files using ' \
        'Redis')
    parser.add_argument('file1', help='first file')
    parser.add_argument('file2', help='second file')
    parser.add_argument('identity_col', metavar='identity column',
        help='identity column name')

    parser.add_argument('--ignore', help='Columns to ignore',
        nargs='+', default=[])

    parser.add_argument('--noadd', help='Do not add entries into Redis',
       action='store_true', default=False)
    parser.add_argument('--noscan', help='Do not scan',
       action='store_true', default=False)

    args=parser.parse_args(argv[1:])

    file1=args.file1
    file2=args.file2
    identity_col=[] or args.identity_col
    ignore=args.ignore

    noadd=args.noadd
    noscan=args.noscan

    # open a redis connection
    r=redis.Redis()

    compare(file1, file2, identity_col, r, ignore_columns=ignore, add=not noadd, scan=not noscan)

if __name__ == "__main__":
        sys.exit(main())

